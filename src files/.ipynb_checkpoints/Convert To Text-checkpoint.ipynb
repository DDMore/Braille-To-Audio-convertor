{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.ndimage import convolve\n",
    "from sklearn.learning_curve import learning_curve\n",
    "from skimage import draw, data, io, segmentation, color, exposure\n",
    "from skimage.measure import regionprops\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.transform import resize \n",
    "from skimage.transform import warp \n",
    "from PIL import Image\n",
    "from sklearn import svm\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All utility functions \n",
    "\n",
    "def img_round(x, base=75):\n",
    "\n",
    "    return (base * math.floor(float(x)/base))\n",
    "vround = np.vectorize(img_round) \n",
    "\n",
    "def get_img(i, size):\n",
    "    img = Image.open('/home/dmm/ocrfiless/train/'+ str(i+1) + '.bmp')\n",
    "    img = img.convert(\"L\")\n",
    "    img = img.resize((size,size))\n",
    "    image = np.asarray(img)\n",
    "    image.setflags(write=True)\n",
    "    return image\n",
    "\n",
    "def nudge_dataset(X, Y, size):\n",
    "    direction_vectors = [\n",
    "        [[0, 1, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [1, 0, 0],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, 0, 0]],\n",
    "\n",
    "        [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 1, 0]]]\n",
    "\n",
    "    shift = lambda x, w: convolve(x.reshape((size, size)), mode='constant',\n",
    "                                  weights=w).ravel()\n",
    "    X = np.concatenate([X] +\n",
    "                       [np.apply_along_axis(shift, 1, X, vector)\n",
    "                        for vector in direction_vectors])\n",
    "    Y = np.concatenate([Y for _ in range(5)], axis=0)\n",
    "    return X, Y\n",
    "\n",
    "def show_img(img):\n",
    "    width = 5.0\n",
    "    height = img.shape[0]*width/img.shape[1]\n",
    "    f = plt.figure(figsize=(width, height))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "def trimString(Str):\n",
    "    i=0\n",
    "    S=\"\"\n",
    "    for ch in Str:\n",
    "        if ch==\" \":\n",
    "            if i==0:\n",
    "                print(ch,end=\"\")\n",
    "                i=i+1\n",
    "                S=S+ch\n",
    "        else:\n",
    "            #print(ch,end=\"\")\n",
    "            i=0\n",
    "            S=S+ch\n",
    "    return S        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10141, 2500) (10141,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('/home/dmm/ocrfiless/a.csv', header=0)\n",
    "raw_y = np.asarray(df['Class'])\n",
    "raw_x = np.asarray([get_img(i, 50) for i in df.index]).astype(float)\n",
    "x = np.asarray([i.ravel() for i in raw_x])\n",
    "y = raw_y\n",
    "print (x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_test_img(i):\n",
    "    img = Image.open('/home/dmm/Braille-To-Audio-convertor/created images/Braille_Characters/'+ str(i) + '.bmp')\n",
    "    img = img.convert(\"L\")\n",
    "    img = img.resize((50,50))\n",
    "    image = np.asarray(img)\n",
    "    image.setflags(write=True)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y)\n",
    "\n",
    "X_train, Y_train = nudge_dataset(X_train, Y_train, 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"knn = KNeighborsClassifier(n_neighbors=5)\\nknn.fit(X_train, Y_train)\\nprint('DONE')\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, Y_train)\n",
    "print('DONE')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from random import randint\\n\\nrandom_image = 898\\nString=\"\"\\nfor i in range(1,random_image):\\n    char=str(knn.predict([get_test_img(i).ravel()])).strip(\\'[]\\'\\')\\n    if char==\"space\":\\n        char=\" \"\\n    print(char,end=\"\")    \\n    String=String+char \\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''from random import randint\n",
    "\n",
    "random_image = 898\n",
    "String=\"\"\n",
    "for i in range(1,random_image):\n",
    "    char=str(knn.predict([get_test_img(i).ravel()])).strip('[]\\'')\n",
    "    if char==\"space\":\n",
    "        char=\" \"\n",
    "    print(char,end=\"\")    \n",
    "    String=String+char \n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=1, kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit svm model\n",
    "\n",
    "model = svm.SVC(kernel='linear', gamma=1) \n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " walchand college of engineering is situated midway between sangli and miraj cities at uishrambag* sangli. q the wce camqus is located on about y ij q acres of land on southern side of q sangli e- miraj road. q q in y aidg* the college made a modest beginning as new engineering q college* with a single qrogram leading q to e b.e e. ciuil degree. q in the year y aiee* the college was renamed as walchand college of engineering q as qart of the new arrangements q and qursuant to the rehabilitation and deueloqment qrogram mainly funded by q seth walchand hirachand memorial trust q and the gouernment. q the gouernment aqqointed an ad hoc committee for conducting the q college from may y aiee* later q reqlaced by the administratiue q council in y aief. q the ad hoc committee added two q more degree qrograms in e b.e e. mechanical and e b.e e. electrical in y aiee with the intake q of y bj each.  walchand college of engineering is situated midway between sangli and miraj cities at uishrambag* sangli. q the wce camqus is located on about y ij q acres of land on southern side of q sangli e- miraj road. q q in y aidg* the college made a modest beginning as new engineering q college* with a single qrogram leading q to e b.e e. ciuil degree. q in the year y aiee* the college was renamed as walchand college of engineering q as qart of the new arrangements q and qursuant to the rehabilitation and deueloqment qrogram mainly funded by q seth walchand hirachand memorial trust q and the gouernment. q the gouernment aqqointed an ad hoc committee for conducting the q college from may y aiee* later q reqlaced by the administratiue q council in y aief. q the ad hoc committee added two q more degree qrograms in e b.e e. mechanical and e b.e e. electrical in y aiee with the intake q of y bj each. \n"
     ]
    }
   ],
   "source": [
    "#Predict Output using .bpm character images\n",
    "\n",
    "from random import randint\n",
    "\n",
    "random_image = 2358\n",
    "String=\"\"\n",
    "for i in range(1,random_image):\n",
    "    char=str(model.predict([get_test_img(i).ravel()])).strip('[]\\'')\n",
    "    if char==\"space\":\n",
    "        char=\" \"       \n",
    "    String=String+char \n",
    "output_text=trimString(String)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "No text to speak",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-77d400888227>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgTTS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'en'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gtts/tts.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, text, lang, slow, debug)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No text to speak'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: No text to speak"
     ]
    }
   ],
   "source": [
    "tts = gTTS(text=output_text, lang='en')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
